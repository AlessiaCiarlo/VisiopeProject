{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHFgp6d3uFhe"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArJgjEUrCHtR"
      },
      "outputs": [],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYemIoLzul94"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import csv\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "\n",
        "import torchvision as TV\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "import timm\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0Z6QsFjmMXH"
      },
      "outputs": [],
      "source": [
        "data_dir_path = '/content/drive/MyDrive/VISIOPE_Project/DATASET/CLASSIFICATION_dataset/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM4-iXhol2la"
      },
      "source": [
        "# Statistics' dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LdeEkV2l1mC"
      },
      "outputs": [],
      "source": [
        "# number of images in each class for training datasets\n",
        "data_dic = {}\n",
        "dict_label = {0: 'biodegradable', 1 : 'glass', 2 : 'paper', 3 : 'plastic', 4 : 'special', 5 : 'trash'}\n",
        "# Specify the file name\n",
        "csv_file_name = ['train_class_balanced.csv', 'val_class_balanced.csv', 'test_class_balanced.csv']\n",
        "\n",
        "# PER LEGGERE DAI CSV\n",
        "for file in csv_file_name:\n",
        "  with open(data_dir_path+file, 'r', newline='') as csvfile:\n",
        "      csv_reader = csv.reader(csvfile)\n",
        "      for row in csv_reader:\n",
        "        if dict_label[int(row[1])] not in data_dic:\n",
        "          data_dic[dict_label[int(row[1])]] = 1\n",
        "        data_dic[dict_label[int(row[1])]] += 1\n",
        "\n",
        "data_df= pd.Series(data_dic)\n",
        "plt.figure(figsize = (15, 6))\n",
        "data_df.sort_values().plot(kind = 'bar')\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Number of images')\n",
        "\n",
        "# fare il grafico leggendo i csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7EKS-Yju6gw"
      },
      "source": [
        "# DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gde7Em8Gu5ky"
      },
      "outputs": [],
      "source": [
        "#USARE SE NON VOGLIAMO LO SPLIT DEI DATASET FISSO\n",
        "\n",
        "# class CustomImageFolder(ImageFolder):\n",
        "#   def __init__(self, root, transform=None, target_transform=None):\n",
        "#     super(CustomImageFolder, self).__init__(root, transform, target_transform)\n",
        "\n",
        "#   def __getitem__(self, index):\n",
        "#     path, target = self.samples[index]\n",
        "\n",
        "#     # Print the image path and label during loading\n",
        "#     #print(f\"Image path: {path}, Label: {target}\")\n",
        "\n",
        "#     # Load the image using the parent class's __getitem__ method\n",
        "#     img = super(CustomImageFolder, self).__getitem__(index)\n",
        "\n",
        "#     # Additional processing or modifications can be done here if needed\n",
        "\n",
        "#     return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUpYa0y_YIpB"
      },
      "outputs": [],
      "source": [
        "class ClassificationDataset(Dataset):\n",
        "  def __init__(self, csv_file, transform=None):\n",
        "    self.data_frame = pd.read_csv(csv_file)\n",
        "    self.transform = transform\n",
        "    self.root_dir = '/content/drive/MyDrive/VISIOPE_Project/DATASET/CLASSIFICATION_dataset/'\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_frame)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = self.data_frame.iloc[idx, 0]\n",
        "    label = int(self.data_frame.iloc[idx, 1])\n",
        "\n",
        "    # Load image\n",
        "    image = Image.open(self.root_dir+img_path).convert(\"RGB\")\n",
        "\n",
        "    # Apply transformations\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt8RkCynv4eZ"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "#\n",
        "# Create an instance of your custom dataset\n",
        "#custom_dataset = CustomImageFolder(root=data_dir_path, transform=transform)\n",
        "\n",
        "# train_size = int(0.7 * len(custom_dataset))\n",
        "# val_size = int(0.15 * len(custom_dataset))\n",
        "# test_size = len(custom_dataset) - train_size - val_size\n",
        "\n",
        "# # Suddivisione del dataset\n",
        "# train_dataset, val_dataset, test_dataset = random_split(custom_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "train_dataset = ClassificationDataset(data_dir_path+'train_class_balanced.csv', transform)\n",
        "val_dataset = ClassificationDataset(data_dir_path+'val_class_balanced.csv', transform)\n",
        "test_dataset = ClassificationDataset(data_dir_path+'test_class_balanced.csv', transform)\n",
        "\n",
        "# Create a DataLoader to handle batching and shuffling\n",
        "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIgO30sPznwA"
      },
      "outputs": [],
      "source": [
        "#numero dei batch\n",
        "print(len(train_loader))\n",
        "print(len(val_loader))\n",
        "print(len(test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPRGGpx_Xp-3"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9T1HC6Av8rX"
      },
      "outputs": [],
      "source": [
        "# Define a custom classifier (replace with your own if needed)\n",
        "class CustomClassifierModel(nn.Module):\n",
        "\n",
        "  def __init__(self, num_classes, model_type):\n",
        "    super(CustomClassifierModel, self).__init__()\n",
        "    self.model_type = model_type\n",
        "\n",
        "    if self.model_type == 'eff':\n",
        "      self.model = timm.create_model(\"efficientnet_b0\", pretrained=True)\n",
        "      in_features = self.model.classifier.in_features\n",
        "      self.model.classifier = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    if self.model_type == 'resnet18':\n",
        "      self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "      in_features = self.resnet.fc.in_features\n",
        "      self.resnet.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    if self.model_type == 'resnet50':\n",
        "      self.resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "      in_features = self.resnet.fc.in_features\n",
        "      self.resnet.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    if self.model_type == 'vgg16':\n",
        "      self.model = models.vgg16(weights=models.VGG16_Weights.DEFAULT, progress = True) #pretrained=True\n",
        "      self.model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x):     #gli passo anche il label??\n",
        "    if self.model_type == 'resnet18': return self.resnet(x)\n",
        "    if self.model_type == 'resnet50': return self.resnet(x)\n",
        "    if self.model_type == 'eff': return self.model(x)\n",
        "    if self.model_type == 'vgg16': return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdUVgBYlwAII"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "num_classes = 6\n",
        "model_type = 'vgg16'\n",
        "#'resnet50'\n",
        "#'vgg16'\n",
        "#'efficientNet'\n",
        "\n",
        "model = CustomClassifierModel(num_classes, model_type)\n",
        "model.to(device)    # model to put on GPU before to define the optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()   #provare altre error function, usare crossentropy con i pesi per unbalanced data\n",
        "#criterion = TV.ops.sigmoid_focal_loss() #FocalLoss(input, target)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.001) # da provare in generale e da provare con effnet\n",
        "\n",
        "#scheduler = optim.lr_scheduler.LinearLR(optimizer, start_factor = 0.001, end_factor = 0.3, total_iters = min(1000, len(train_loader)-1))\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer) #lascio parametri di default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oXGP4Q5Xs8E"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7t8sZefnwDsX"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5\n",
        "c = 0\n",
        "k = 0\n",
        "\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "accuracy = []\n",
        "accuracy_v = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  #METRICS FOR EACH BATCH\n",
        "  running_loss_train = 0.0\n",
        "  correct_predictions_train = 0\n",
        "  total_samples_train = 0\n",
        "\n",
        "  running_loss_val = 0.0\n",
        "  correct_predictions_val = 0\n",
        "  total_samples_val = 0\n",
        "\n",
        "  true_label_train = []\n",
        "  true_label_val = []\n",
        "\n",
        "  pred_label_train = []\n",
        "  pred_label_val = []\n",
        "\n",
        "  print('TRAIN')\n",
        "\n",
        "  for images, labels in train_loader:\n",
        "    c += 1\n",
        "    if  c%10 == 0: print(c)\n",
        "    x = images.to(device)\n",
        "    y = labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update statistics\n",
        "    running_loss_train += loss.item()\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total_samples_train += labels.size(0)\n",
        "    correct_predictions_train += (predicted == y).sum().item()\n",
        "\n",
        "    y = y.cpu()\n",
        "    predicted = predicted.cpu()\n",
        "\n",
        "    for elem in y: true_label_train.append(elem)\n",
        "    for elem in predicted: pred_label_train.append(elem)\n",
        "\n",
        "  # scheduler.step(running_loss_train)      #it can be in or out the batch loop/epochs... try with updates for each epoch\n",
        "\n",
        "  # Calculate accuracy and average loss for the epoch\n",
        "  accuracy_train = correct_predictions_train / total_samples_train\n",
        "  average_loss_train = running_loss_train / len(train_loader)\n",
        "\n",
        "  print('VAL')\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "      k += 1\n",
        "      if  k%5 == 0: print(k)\n",
        "      x = images.to(device)\n",
        "      y = labels.to(device)\n",
        "      outputs = model(x)\n",
        "      loss = criterion(outputs, y)\n",
        "\n",
        "      # Update statistics\n",
        "      running_loss_val += loss.item()\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total_samples_val += labels.size(0)\n",
        "      correct_predictions_val += (predicted == y).sum().item()\n",
        "\n",
        "      y = y.cpu()\n",
        "      predicted = predicted.cpu()\n",
        "\n",
        "      for elem in y: true_label_val.append(elem)\n",
        "      for elem in predicted: pred_label_val.append(elem)\n",
        "\n",
        "    scheduler.step(running_loss_val)      #it can be in or out the batch loop/epochs... try with updates for each epoch\n",
        "\n",
        "    # Calculate accuracy and average loss for the epoch\n",
        "    accuracy_val = correct_predictions_val / total_samples_val\n",
        "    average_loss_val = running_loss_val / len(val_loader)\n",
        "\n",
        "    train_loss.append(average_loss_train)\n",
        "    val_loss.append(average_loss_val)\n",
        "    accuracy.append(accuracy_train)\n",
        "    accuracy_v.append(accuracy_val)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss train: {average_loss_train:.4f}, Accuracy train: {accuracy_train * 100:.2f}%, Loss val: {average_loss_val:.4f}, Accuracy val: {accuracy_val * 100:.2f}%\")\n",
        "\n",
        "print(\"TRAINING REPORT\")\n",
        "print(classification_report(true_label_train, pred_label_train, digits = 4))\n",
        "\n",
        "print(\"VALIDATION REPORT\")\n",
        "print(classification_report(true_label_val, pred_label_val, digits = 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhsTlqRFkKkP"
      },
      "outputs": [],
      "source": [
        "epochs = range(1, num_epochs + 1)\n",
        "\n",
        "# Plotting training and validation loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.plot(epochs, train_loss, label='Training Loss', color = 'blue')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss', color = 'red')\n",
        "plt.plot(epochs, accuracy, label='Training Accuracy', color='green')\n",
        "plt.plot(epochs, accuracy_v, label='Validation Accuracy', color='black')\n",
        "\n",
        "plt.title('Metrics')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss / Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SJ5ve1y4Vtb"
      },
      "outputs": [],
      "source": [
        "model_path = '/content/drive/MyDrive/VISIOPE_Project/weights/pesi_classification/4_ep_vgg_64b_FIX_SETS_bal_lr.pth'\n",
        "torch.save(model.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CONFUSION MATRIX TRAINING"
      ],
      "metadata": {
        "id": "9_9JsizGu6ax"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBZ9m3db6HnQ"
      },
      "outputs": [],
      "source": [
        "label = ['biodegradable','glass','paper','plastic', 'special', 'trash']\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(true_label_train, pred_label_train)\n",
        "precision = precision_score(true_label_train, pred_label_train, average = 'weighted')\n",
        "recall = recall_score(true_label_train, pred_label_train, average = 'weighted')\n",
        "f1 = f1_score(true_label_train, pred_label_train, average = 'weighted')\n",
        "conf_matrix = confusion_matrix(true_label_train, pred_label_train)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "# Crea una heatmap utilizzando seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=np.unique(label), yticklabels=np.unique(label))\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9QUoqopX2CG"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlBXhTB2-Tn4"
      },
      "outputs": [],
      "source": [
        "csv_file_path = data_dir_path+'test_class.csv'\n",
        "df_test = pd.read_csv(csv_file_path)\n",
        "\n",
        "true_lab = []\n",
        "pred_lab = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for i in range(len(df_test)):\n",
        "    img_path = df_test.iloc[i, 0]\n",
        "    label = int(df_test.iloc[i, 1])\n",
        "\n",
        "    # Load image\n",
        "    image = Image.open(data_dir_path+img_path).convert(\"RGB\")\n",
        "    image = transform(image)\n",
        "\n",
        "    x = image.to(device)\n",
        "    y = label.to(device)\n",
        "    outputs = model(x)\n",
        "    # Calculate metrics as needed\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    y = y.cpu()\n",
        "    predicted = predicted.cpu()\n",
        "\n",
        "    for elem in labels: true_lab.append(elem)\n",
        "    for elem in predicted: pred_lab.append(elem)\n",
        "\n",
        "  accuracy = accuracy_score(true_lab, pred_lab)\n",
        "  precision = precision_score(true_lab, pred_lab, average = 'weighted')\n",
        "  recall = recall_score(true_lab, pred_lab, average = 'weighted')\n",
        "  f1 = f1_score(true_lab, pred_lab, average = 'weighted')\n",
        "  conf_matrix = confusion_matrix(true_lab, pred_lab)\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "#print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n",
        "# Crea una heatmap utilizzando seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=np.unique(label), yticklabels=np.unique(label))\n",
        "\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "print(\"Test Report\")\n",
        "print(classification_report(true_lab, pred_lab, digits = 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UZO3efKyrwA"
      },
      "outputs": [],
      "source": [
        "#TEST\n",
        "\n",
        "# Evaluation loop (replace this with your own evaluation logic)\n",
        "\n",
        "dir_label = {0 : 'biodegradable', 1 : 'glass', 2 : 'paper', 3 : 'plastic', 4 : 'special', 5 : 'trash'}\n",
        "\n",
        "true_lab = []\n",
        "pred_lab = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for inputs, labels in test_loader:\n",
        "    x = inputs.to(device)\n",
        "    y = labels.to(device)\n",
        "    outputs = model(x)\n",
        "    # Calculate metrics as needed\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    y = y.cpu()\n",
        "    predicted = predicted.cpu()\n",
        "\n",
        "    # for i in range(128):\n",
        "    #   if y[i] != predicted[i]: print('TRUE', dir_label[y[i].item()], 'PREDICT', dir_label[predicted[i].item()])\n",
        "\n",
        "    for elem in labels: true_lab.append(elem)\n",
        "    for elem in predicted: pred_lab.append(elem)\n",
        "\n",
        "  accuracy = accuracy_score(true_lab, pred_lab)\n",
        "  precision = precision_score(true_lab, pred_lab, average = 'weighted')\n",
        "  recall = recall_score(true_lab, pred_lab, average = 'weighted')\n",
        "  f1 = f1_score(true_lab, pred_lab, average = 'weighted')\n",
        "  conf_matrix = confusion_matrix(true_lab, pred_lab)\n",
        "\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "#print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n",
        "# Crea una heatmap utilizzando seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=np.unique(label), yticklabels=np.unique(label))\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "print(\"Test Report\")\n",
        "print(classification_report(true_lab, pred_lab, digits = 4))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}